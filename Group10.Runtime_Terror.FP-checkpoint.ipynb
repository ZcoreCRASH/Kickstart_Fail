{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.plotting import figure, show\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read CSV file and then load into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/dakav/Downloads/archive/kickstarter_data_full.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m path\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/dakav/Downloads/archive/kickstarter_data_full.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m initdf\u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/dakav/Downloads/archive/kickstarter_data_full.csv'"
     ]
    }
   ],
   "source": [
    "path= r\"C:/Users/dakav/Downloads/archive/kickstarter_data_full.csv\"\n",
    "initdf= pd.read_csv(path)\n",
    "# initdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inferred Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "# Schema information\n",
    "initdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Columns with Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "\n",
    "print([col for col in initdf.columns if initdf[col].isnull().any()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After running the above fucntion, we found out the columns with missing values to handle them.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns 'blurb', blurb_len', 'blurb_len_clean', 'location', 'name', 'country', 'is_starred', friends', 'permissions', 'is_backing'  have missing values which are required to be handled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking rows for which specified column contains null\n",
    "def nonnullcheck(df, col):\n",
    "    return df[col][df[col].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check column values of null values \n",
    "def nullcheck(df, col):\n",
    "    return df[col][df[col].isna()]\n",
    "\n",
    "#insert the column name for which you wish to check\n",
    "nullcheck(initdf,'blurb_len_clean') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling blurb\n",
    "initdf[\"blurb\"].fillna(\"Missing blurb\", inplace=True)\n",
    "initdf[\"blurb_len\"].fillna(0, inplace=True)\n",
    "initdf[\"blurb_len_clean\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "initdf[['blurb','blurb_len','blurb_len_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking null rows for location\n",
    "nullcheck(initdf,'location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDLING LOCATION NULL VALUES\n",
    "# Replacing the Null values in location column with \"No Location Specified\"\n",
    "initdf[\"location\"].fillna(\"No location specified\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chekcing 'name', 'location' and 'country' for rows which has unspecified location\n",
    "initdf[['name', 'location', 'country']][initdf['location'] == \"No location specified\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking null values in columns: 'is_starred', friends', 'permissions' &'is_backing'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checing the Non-null Values and evaluating their impact. \n",
    "nonnullcheck(initdf, 'is_backing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checing the Non-null Values and evaluating their impact. \n",
    "nonnullcheck(initdf, 'is_starred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checing the Non-null Values and evaluating their impact. \n",
    "\n",
    "nonnullcheck(initdf, 'friends')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checing the Non-null Values and evaluating their impact. \n",
    "\n",
    "nonnullcheck(initdf, 'permissions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DROPPING UNNECESSARY COLUMNS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the maximum values columns 'friends', 'is_starred', 'is_backing'& 'permissions' is either Null or inserted by the author which will also not affect out visualisations, we will drop these four columns.\n",
    "\n",
    "initdf.drop(['friends', 'is_starred', 'is_backing', 'permissions'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the look of new Dataframe\n",
    "initdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "nullcheck(initdf, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "\n",
    "nonnullcheck(initdf, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For all the Null values in categories, we are grouping them and assigning them a value for a cleaner outlay of the dataset.\n",
    "\n",
    "initdf[['name','category']][initdf['category']==\"Uncategorized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling categories\n",
    "initdf[\"category\"].fillna(\"Uncategorized\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "\n",
    "#check if all null values have been handled\n",
    "print([col for col in initdf.columns if initdf[col].isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "nonnullcheck(initdf, 'name_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "nullcheck(initdf, 'name_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "initdf[['name','name_len','name_len_clean']][initdf['name_len']==0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPPING INCOMPLETE DATA ROWS\n",
    "\n",
    "#initdf.drop(labels=[1411,6744,9239,11708,14805], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "# Checking for Null values in Dataframe\n",
    "\n",
    "initdf.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALIDATION TEST CELLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "\n",
    "# initdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Checking count of categories by their states\n",
    "# initdf.groupby(\"state\")[[\"category\"]].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Count the number of unique values\n",
    "# initdf[[\"category\",\"state\"]].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "\n",
    "# List number of unique values\n",
    "# initdf[\"state\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "\n",
    "# initdf[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING DATAFRAMES BY STATE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_df = initdf[initdf[\"state\"] == \"failed\"].groupby([\"category\"])[['state']].count().reset_index()\n",
    "successful_df = initdf[initdf[\"state\"] == \"successful\"].groupby([\"category\"])[['state']].count().reset_index()\n",
    "canceled_df = initdf[initdf[\"state\"] == \"canceled\"].groupby([\"category\"])[['state']].count().reset_index()\n",
    "live_df = initdf[initdf[\"state\"] == \"live\"].groupby([\"category\"])[['state']].count().reset_index()\n",
    "suspended_df = initdf[initdf[\"state\"] == \"suspended\"].groupby([\"category\"])[['state']].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING DEFAULT DICTIONARY FOR STATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "categories_dict = {\n",
    "    'Academic':0,\n",
    "    'Places':0,\n",
    "    'Uncategorized':0,\n",
    "    'Blues':0,\n",
    "    'Restaurants':0,\n",
    "    'Webseries':0, \n",
    "    'Thrillers':0, \n",
    "    'Shorts':0, \n",
    "    'Web':0, \n",
    "    'Apps':0, \n",
    "    'Gadgets':0,\n",
    "    'Hardware':0, \n",
    "    'Festivals':0, \n",
    "    'Plays':0, \n",
    "    'Musical':0, \n",
    "    'Flight':0, \n",
    "    'Spaces':0,\n",
    "    'Immersive':0, \n",
    "    'Experimental':0, \n",
    "    'Comedy':0, \n",
    "    'Wearables':0, \n",
    "    'Sound':0,\n",
    "    'Software':0, \n",
    "    'Robots':0, \n",
    "    'Makerspaces':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    METHOD TO RETURN SERIES PER STATE FOR VISUALIZATION\n",
    "def populating_state_series(df):\n",
    "\n",
    "    shallow_copy = categories_dict.copy()\n",
    "    for i in range(len(df)):\n",
    "        if df['category'][i] in shallow_copy:\n",
    "            shallow_copy[df['category'][i]] = df['state'][i]\n",
    "#     print(shallow_copy)\n",
    "    return list(shallow_copy.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "\n",
    "# categories_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALLING METHOD TO RETURN SERIES PER STATE FOR VISUALIZATION\n",
    "\n",
    "categories = list(categories_dict.keys())\n",
    "failed = populating_state_series(failed_df)\n",
    "successful = populating_state_series(successful_df)\n",
    "canceled = populating_state_series(canceled_df)\n",
    "live = populating_state_series(live_df)\n",
    "suspended = populating_state_series(suspended_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# print(categories)\n",
    "# print(successful)\n",
    "# print(failed)\n",
    "# print(canceled)\n",
    "# print(live)\n",
    "# print(suspended)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# print(len(canceled), len(successful), len(live), len(suspended), len(failed))\n",
    "# states = list(initdf[\"state\"].unique())\n",
    "# print(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. VISUALISATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 BAR CHART "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.plotting import show, output_notebook, output_file\n",
    "output_notebook()\n",
    "\n",
    "categories = list(categories_dict.keys())\n",
    "states = list(initdf[\"state\"].unique())\n",
    "colors = [\"orange\", \"red\", \"green\",\"blue\", \"silver\"]\n",
    "\n",
    "data = {'categories' : categories}\n",
    "data['failed'] = populating_state_series(failed_df)\n",
    "data['successful'] = populating_state_series(successful_df) \n",
    "data['canceled'] = populating_state_series(canceled_df)\n",
    "data['live'] = populating_state_series(live_df)\n",
    "data['suspended'] = populating_state_series(suspended_df)\n",
    " \n",
    "\n",
    "# print(data)\n",
    "p = figure(x_range=categories, height=500, title=\"States of Kicstarter by Categories\",\n",
    "           toolbar_location=None, tools='hover', tooltips=\"$name @categories: @$name\")\n",
    "\n",
    "p.vbar_stack(states, x='categories', width=0.9, color=colors, source=data,\n",
    "             legend_label=states)\n",
    "\n",
    "p.y_range.start = 0\n",
    "p.x_range.range_padding = 0.1\n",
    "p.xgrid.grid_line_color = None\n",
    "p.axis.minor_tick_line_color = None\n",
    "p.outline_line_color = None\n",
    "p.legend.location = \"top_left\"\n",
    "p.legend.orientation = \"horizontal\"\n",
    "p.xaxis.major_label_orientation = \"vertical\"\n",
    "p.xaxis.axis_label = 'Categories'\n",
    "p.yaxis.axis_label = 'No.of Kickstarters'\n",
    "\n",
    "\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Inference from the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have total 25 Categories which contain 20627 kickstarters combined. \n",
    "\n",
    "\n",
    "\n",
    "- Top 5 famous categires with most kickstarters are:\n",
    "    1. Web \n",
    "    2. Hardware \n",
    "    3. Software \n",
    "    4. Gadgets \n",
    "    5. Uncategorized \n",
    "    \n",
    "    \n",
    "- Top 5 Successful categories are:\n",
    "    1. Hardware \n",
    "    2. Uncategorized\n",
    "    3. Plays\n",
    "    4. Gadgets\n",
    "    5. Musical\n",
    "    \n",
    "    \n",
    "- Top 5 Failed catergories are:\n",
    "    1. Web \n",
    "    2. Software\n",
    "    3. Hardware \n",
    "    4. Gadgets \n",
    "    5. Uncategorized \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD TO RETURN Categories PER STATE FOR VISUALIZATION\n",
    "\n",
    "def populating_categories_dictionary(df):\n",
    "    shallow_copy = categories_dict.copy()\n",
    "    for i in range(len(df)):\n",
    "        if df['category'][i] in shallow_copy:\n",
    "            shallow_copy[df['category'][i]] = df['state'][i]\n",
    "#             shallow_copy['academic'] = 20\n",
    "#     print(shallow_copy)\n",
    "    return shallow_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 PIE CHART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "import pandas as pd\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.palettes import Category20c\n",
    "import random\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import cumsum\n",
    "from bokeh.models import LabelSet, ColumnDataSource\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "pie_colors=['#039d72','#45BA7E','#de324c', '#f4895f', '#f8e16f',\n",
    "            '#95cf92','#369acc','#9656a2','#B74E09','#61B22E',\n",
    "            '#4B2DF7','#5EB999','#5DBDE7','#DD629B','#B2A6A3',\n",
    "            '#C9212C','#E63DC4', '#A13C50','#4E4327','#76A9CA',\n",
    "            '#DD7C03','#DD7C03','#80D077','#D84CE4', '#D67956']\n",
    "\n",
    "\n",
    "total_df = initdf.groupby(\"category\")[\"state\"].count().reset_index()\n",
    "x = populating_categories_dictionary(total_df)\n",
    "data = pd.Series(x).reset_index(name='value').rename(columns={'index':'category'})\n",
    "# print(data)\n",
    "\n",
    "data['angle'] = data['value']/data['value'].sum() * 2*pi\n",
    "data['color'] = ['#039d72','#45BA7E','#de324c', '#f4895f', '#f8e16f',\n",
    "            '#95cf92','#369acc','#9656a2','#B74E09','#61B22E',\n",
    "            '#4B2DF7','#5EB999','#5DBDE7','#DD629B','#B2A6A3',\n",
    "            '#C9212C','#E63DC4', '#A13C50','#4E4327','#76A9CA',\n",
    "            '#DD7C03','#DD7C03','#80D077','#D84CE4', '#D67956']\n",
    "\n",
    "p = figure(plot_height=800, title=\"Pie Chart\", toolbar_location=None,\n",
    "           tools=\"hover\", tooltips=\"@category: @value\", x_range=(-0.8, 1.8))\n",
    "\n",
    "p.wedge(x=0, y=1, radius=0.8,\n",
    "        start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n",
    "        line_color=\"white\", fill_color='color', legend='category', source=data)\n",
    "\n",
    "data[\"value\"] = data['value'].astype(str)\n",
    "data[\"value\"] = data[\"value\"].str.pad(35, side = \"left\")\n",
    "source = ColumnDataSource(data)\n",
    "\n",
    "labels = LabelSet(x=0, y=1, text='value',\n",
    "        angle=cumsum('angle', include_zero=True), source=source, render_mode='canvas')\n",
    "\n",
    "p.add_layout(labels)\n",
    "\n",
    "p.axis.axis_label=None\n",
    "p.axis.visible=False\n",
    "# p.grid.grid_line_color = None\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1Inference from the Pie Chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above visualisation consist of a simple pie chart showing distribution of all the Kickstarters in various categories\n",
    "\n",
    "\n",
    "\n",
    "- Pie chart suggests that most of the kickstarters are famous amongts the following categories:\n",
    "   1. WEB\n",
    "   2. HARDWARE\n",
    "   3. SOFTWARE\n",
    "   4. GADGETS\n",
    "   5. UNCATEGORIZED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CREATING A DATAFRAME FOR LINE CHART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Groupby, Checking count of kickstarter(name) by their launch year which have state as successful. \n",
    "\n",
    "initdf[initdf['state'] == 'successful'].groupby('launched_at_yr')['name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Groupby, Checking count of kickstarter(name) by their launch year which have state as Failed. \n",
    "\n",
    "initdf[initdf['state'] == 'failed'].groupby('launched_at_yr')['name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALLING METHOD TO RETURN SERIES PER Launch Year  FOR VISUALIZATION\n",
    "\n",
    "# This method will call all the kickstarters according to their launch year.\n",
    "total_by_yr = initdf.groupby(['launched_at_yr'])[['name']].count().reset_index()\n",
    "\n",
    "# This method will call all the sucessful kickstarters according to their launch year.\n",
    "successful_by_yr = initdf[initdf['state'] == 'successful'].groupby('launched_at_yr')['name'].count().reset_index()\n",
    "\n",
    "# This method will call all the failed kickstarters according to their launch year.\n",
    "failed_by_yr = initdf[initdf['state'] == 'failed'].groupby('launched_at_yr')['name'].count().reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION TEST CELL ------------------------------------------------------------------------------------------------\n",
    "#list(successful_by_yr['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 LINE GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "# prepare some data\n",
    "x = list(total_by_yr['launched_at_yr']) #list of years\n",
    "y1 = list(total_by_yr['name']) #count(name/anything) for total by year \n",
    "y2 = list(failed_by_yr['name']) #count(name/anything) for failed by year \n",
    "y3 = list(successful_by_yr['name']) #count(name/anything) for successful by year \n",
    "\n",
    "# create a new plot with a title and axis labels\n",
    "p = figure(title=\"Total campaign vs Success/Failure rate\", x_axis_label=\"Year\", y_axis_label=\"Value\", plot_width = 600, plot_height = 400)\n",
    "\n",
    "# add multiple renderers\n",
    "p.line(x, y1, legend_label=\"Total.\", color=\"blue\", line_width=2)\n",
    "p.line(x, y2, legend_label=\"Failed\", color=\"red\", line_width=2)\n",
    "p.line(x, y3, legend_label=\"Successful\", color=\"green\", line_width=2)\n",
    "# show the results\n",
    "\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Inference from Line Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The graph shows the camparision between the Total campaigns, the total Failed and succesful campaign\n",
    "\n",
    "- From the graph we can infer that, there are more number of failed campaings than successful ones. \n",
    "\n",
    "- Most of the campaigns fromt his dataset is from the year 2013 to year 2018.\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 HEAT MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pivot_table= initdf.pivot_table(index=\"category\",columns=\"country\",values=\"backers_count\",aggfunc='mean')\n",
    "color = plt.get_cmap('RdYlGn') \n",
    "color.set_bad('maroon')\n",
    "sns.heatmap(pivot_table,cmap=color)\n",
    "print(\"HeatMap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 Inference from Heat Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The heat map shows that for certain categories like flight, hardware and restaurants, there are a large number of backers in a single particular country such as China, Sweden and the Netherlands respectively for these categories. So launching these type of kickstarters in these countries will increase their success rate.\n",
    "\n",
    "- There are a lot of bad values being seen in the heat map marked which are marked in maroon, which indicates that a huge number of kickstarters launched have 0 backers which contributes to them failing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 HISTOGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "sns.histplot(data=initdf,x=\"launched_at_month\",hue=\"state\",bins=12)\n",
    "pyplot.figure(figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 Inference from Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can infer from the histogram that, there is a high success rate for kickstarters launched from May to June. We can use this inference and increase the success rate of kickstartes by launching them in those particular months.\n",
    "\n",
    "\n",
    "- The failure rate seems to be high during December and January and it would be best to avoid those months for starting new projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 BOXPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initdf['usd_goal'] = initdf['goal']*initdf['static_usd_rate'] # To convert currency of goal to US currency\n",
    "boxdf = initdf[['category','SuccessfulBool', 'state', 'launch_to_state_change_days']]\n",
    "boxdf.groupby(initdf.category).mean().reset_index()\n",
    "failed = boxdf[boxdf['SuccessfulBool']==0][['launch_to_state_change_days','category' ,'state']]\n",
    "success = boxdf[boxdf['SuccessfulBool']==1][['launch_to_state_change_days','category','state']]\n",
    "x = failed['launch_to_state_change_days']\n",
    "y = failed['category']\n",
    "sns.set(rc={'figure.figsize':(15,6)})\n",
    "sns.boxplot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initdf[initdf['SuccessfulBool']==1].describe()['launch_to_state_change_days']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6.1 Inference from boxplot\n",
    " Most of the successful projects are run for 30-35 days. From the visualization, it can be infered that most of the failed projects are run for more than 40-60 days. From the outliers, we can infer that most of the campaigns failed because their duration was too less to have enough time to gather enough funding or run for a long period 50 days and above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterdf = initdf[['usd_goal','category','usd_pledged','SuccessfulBool', 'state','backers_count']]\n",
    "# filtering the failed projects \n",
    "failed = scatterdf[scatterdf['SuccessfulBool']==0][['usd_goal','backers_count','category' ,'usd_pledged','state']]\n",
    "# filtering the successful projects\n",
    "success = scatterdf[scatterdf['SuccessfulBool']==1][['usd_goal','backers_count','category' ,'usd_pledged','state']]\n",
    "sns.set(font_scale=1.3)\n",
    "#Extracting average values for all categories\n",
    "avg1 = failed.groupby(initdf.category).mean().reset_index()\n",
    "avg2 = success.groupby(initdf.category).mean().reset_index()\n",
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(avg1['usd_goal'],avg1['category'], size = avg1['backers_count'], color='r', label='failed')\n",
    "sns.scatterplot(avg2['usd_goal'],avg2['category'], size = avg2['backers_count'], color='g', label='successful')\n",
    "ax.set_xlim(1, 150000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7.1 Inference from Scatter Plot\n",
    "Across all categories, the campaigns are most likely to be successful if their funding goal is below 20000 dollars. The median goal amount of successful projects is 6000 dollars while failed projects is 115171 dollars which is more than double the successful projects. This suggests that projects with a conservative are more likely to attract backers.\n",
    "We can also see that failed projects across all categories have higher funding goals than successful ones. \n",
    "It can also be infered that Gadgets, Hardware and wearables attract more backers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initdf[initdf['SuccessfulBool']==1].describe()['usd_goal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initdf[initdf['SuccessfulBool']==0].describe()['usd_goal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
